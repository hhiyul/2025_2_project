{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1edb0c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, ClassLabel, DatasetDict\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import time\n",
    "from typing import Optional, Tuple, Dict\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ec7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"Densu341/Fresh-rotten-fruit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34df32ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6b4216503b4bd690095b5169e3546e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b0a35e41b247c3972ef4d2d4d98e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78720d499a074ff594995a1daaafb414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/21486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8e8829ef754fd9bf0c9c5c1ef76bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/5372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "remove_labels = [18, 20, 16, 13, 2, 5, 7, 9]\n",
    "labels = np.array(dataset[\"train\"][\"label\"])\n",
    "mask = ~np.isin(labels, remove_labels)\n",
    "\n",
    "# 3. í•„ìš” ì—†ëŠ” ë¼ë²¨ ì œê±°\n",
    "clean_dataset = dataset[\"train\"].select(np.where(mask)[0])\n",
    "\n",
    "# 4. train/val split\n",
    "dataset = clean_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset, val_dataset = dataset[\"train\"], dataset[\"test\"]\n",
    "\n",
    "# 5. ì‹¤ì œ ë‚¨ì€ ë¼ë²¨ ì¸ë±ìŠ¤ ë° ì´ë¦„ ì¶”ì¶œ\n",
    "unique_labels = sorted(set(train_dataset[\"label\"]) | set(val_dataset[\"label\"]))\n",
    "all_labels = [train_dataset.features[\"label\"].int2str(i) for i in unique_labels]\n",
    "\n",
    "# 6. ìƒˆë¡œìš´ ClassLabel ì •ì˜\n",
    "new_classlabel = ClassLabel(num_classes=len(all_labels), names=all_labels)\n",
    "\n",
    "# 7. ë¼ë²¨ ê°’ ì¬ë§¤í•‘\n",
    "def remap_labels(example):\n",
    "    label_name = train_dataset.features[\"label\"].int2str(example[\"label\"])\n",
    "    example[\"label\"] = all_labels.index(label_name)\n",
    "    return example\n",
    "\n",
    "train_dataset = train_dataset.map(remap_labels)\n",
    "val_dataset   = val_dataset.map(remap_labels)\n",
    "\n",
    "train_dataset = train_dataset.cast_column(\"label\", new_classlabel)\n",
    "val_dataset   = val_dataset.cast_column(\"label\", new_classlabel)\n",
    "\n",
    "# 8. ìµœì¢… DatasetDict ìƒì„±\n",
    "final_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": val_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "051a9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cfg:\n",
    "    IMAGE_SIZE = 224  # (H,W) ì „ì²˜ë¦¬ì—ì„œ Resize((224,224)) ê°€ì •\n",
    "    PATCH_DOWN = 16   # CNNìœ¼ë¡œ 1/16 í•´ìƒë„ê¹Œì§€ ë‹¤ìš´ìƒ˜í”Œ (224->14)\n",
    "    D_MODEL = 384     # Transformer ì„ë² ë”© ì°¨ì›\n",
    "    N_HEAD = 6\n",
    "    DEPTH  = 6\n",
    "    MLP_RATIO = 4\n",
    "    DROPOUT = 0.1\n",
    "    ATTN_DROPOUT = 0.1\n",
    "\n",
    "    # í•™ìŠµ ê´€ë ¨\n",
    "    LR = 3e-4\n",
    "    EPOCHS = 10\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_WORKERS = 2\n",
    "    #ì¥¬í”¼í„° ë…¸íŠ¸ë¶ì—ì„  2ì´ìƒ ì•ˆë¨\n",
    "    MIXED_PRECISION = True\n",
    "\n",
    "    # íƒœìŠ¤í¬ í† ê¸€\n",
    "    MULTITASK = False  # True: (ê³¼ì¼ì¢…, ì‹ ì„ ë„) ë‘ ê°œì˜ í—¤ë“œ\n",
    "    NUM_CLASSES = 14   # ë‹¨ì¼ ê³¼ì œì¼ ë•Œ í´ë˜ìŠ¤ ìˆ˜\n",
    "\n",
    "    # ë©€í‹°íƒœìŠ¤í¬ì¼ ë•Œ ê° í—¤ë“œ í´ë˜ìŠ¤ ìˆ˜\n",
    "    NUM_FRUIT = 7\n",
    "    NUM_FRESH = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a692d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])  # ImageNet ê¸°ì¤€\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],\n",
    "                         [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# --------------------------------------------------\n",
    "# PyTorch Dataset ë˜í¼\n",
    "# --------------------------------------------------\n",
    "class FruitHFDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.dataset[idx]\n",
    "        image = sample[\"image\"].convert(\"RGB\")  # RGBA â†’ RGB\n",
    "        label = sample[\"label\"]                # ì´ë¯¸ 0~N-1 ì •ìˆ˜\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# --------------------------------------------------\n",
    "# DataLoader ìƒì„±\n",
    "# --------------------------------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    FruitHFDataset(final_dataset[\"train\"], transform=train_transform),\n",
    "    batch_size=Cfg.BATCH_SIZE,         # ë³´í†µ 32~64\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=Cfg.NUM_WORKERS,       # Cfgì—ì„œ ê´€ë¦¬ (ì˜ˆ: 1)\n",
    "    pin_memory=(device.type == \"cuda\") # âœ… GPUì¼ ë•Œë§Œ True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    FruitHFDataset(final_dataset[\"test\"], transform=val_transform),\n",
    "    batch_size=Cfg.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=Cfg.NUM_WORKERS,\n",
    "    pin_memory=(device.type == \"cuda\") # âœ… ë™ì¼í•˜ê²Œ ì ìš© ê°€ëŠ¥\n",
    ")\n",
    "\n",
    "num_classes = len(final_dataset[\"train\"].features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f39ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹¤ì œ ë¼ë²¨ ì¸ë±ìŠ¤: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
      "ë¼ë²¨ ë§¤í•‘: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16657e22fee84ae0b039e4ec1095f0d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21486 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26a9dd110de46ac82c7e1ba51bfd028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5372 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì¢… í´ë˜ìŠ¤ ê°œìˆ˜: 14\n"
     ]
    }
   ],
   "source": [
    "# 1. ê³ ìœ  ë¼ë²¨ ì¶”ì¶œ\n",
    "unique_labels = sorted(set(final_dataset[\"train\"][\"label\"]) | set(final_dataset[\"test\"][\"label\"]))\n",
    "print(\"ì‹¤ì œ ë¼ë²¨ ì¸ë±ìŠ¤:\", unique_labels)\n",
    "\n",
    "# 2. ì¬ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "label2idx = {old: new for new, old in enumerate(unique_labels)}\n",
    "print(\"ë¼ë²¨ ë§¤í•‘:\", label2idx)\n",
    "\n",
    "# 3. ë§¤í•‘ í•¨ìˆ˜\n",
    "def remap(example):\n",
    "    example[\"label\"] = label2idx[example[\"label\"]]\n",
    "    return example\n",
    "\n",
    "# 4. ë¼ë²¨ ë‹¤ì‹œ ë§¤í•‘\n",
    "final_dataset = final_dataset.map(remap)\n",
    "\n",
    "# 5. í´ë˜ìŠ¤ ê°œìˆ˜ í™•ì¸\n",
    "num_classes = len(unique_labels)\n",
    "print(\"ìµœì¢… í´ë˜ìŠ¤ ê°œìˆ˜:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa003b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ê°„ë‹¨ CNN ë² ì´ìŠ¤ë¼ì¸ (SeparableConv)\n",
    "# - ê³¼ëŒ€ì í•© ì–µì œ: Depthwise Separable, Dropout, GAP\n",
    "# - ë©€í‹°íƒœìŠ¤í¬/ë‹¨ì¼ê³¼ì œ ê³µí†µ ì§€ì› (ê¸°ì¡´ train_loop ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥)\n",
    "# =========================\n",
    "\n",
    "class SeparableConv(nn.Module):\n",
    "    def __init__(self, cin, cout, stride=1, drop=0.0):\n",
    "        super().__init__()\n",
    "        self.dw = nn.Conv2d(cin, cin, kernel_size=3, stride=stride, padding=1, groups=cin, bias=False)\n",
    "        self.dw_bn = nn.BatchNorm2d(cin)\n",
    "        self.pw = nn.Conv2d(cin, cout, kernel_size=1, bias=False)\n",
    "        self.pw_bn = nn.BatchNorm2d(cout)\n",
    "        self.act = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout2d(drop) if drop > 0 else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dw(x); x = self.dw_bn(x); x = self.act(x)\n",
    "        x = self.pw(x); x = self.pw_bn(x); x = self.act(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    ì…ë ¥: (B,3,224,224) ê°€ì •\n",
    "    ë‹¤ìš´ìƒ˜í”Œ: /2 â†’ /2 â†’ /2 â†’ /2 â†’ /2 (ì´ /32, 224â†’7)\n",
    "    ì±„ë„: 32 â†’ 64 â†’ 128 â†’ 192 â†’ 256 (ê°€ë²¼ì›€)\n",
    "    ë¶„ë¥˜: GAP â†’ Dropout â†’ Linear\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 num_classes: Optional[int] = None,\n",
    "                 multitask: bool = False,\n",
    "                 num_fruit: int = 7,\n",
    "                 num_fresh: int = 2,\n",
    "                 drop_block: float = 0.05,\n",
    "                 drop_head: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.multitask = multitask\n",
    "\n",
    "        chs = [32, 64, 128, 192, 256]  # ê°€ë²¼ìš´ ì±„ë„ êµ¬ì„±\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, chs[0], kernel_size=3, stride=2, padding=1, bias=False),  # 224 -> 112\n",
    "            nn.BatchNorm2d(chs[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.stage1 = SeparableConv(chs[0], chs[1], stride=2, drop=drop_block)     # 112 -> 56\n",
    "        self.stage2 = SeparableConv(chs[1], chs[2], stride=2, drop=drop_block)     # 56  -> 28\n",
    "        self.stage3 = SeparableConv(chs[2], chs[3], stride=2, drop=drop_block)     # 28  -> 14\n",
    "        self.stage4 = SeparableConv(chs[3], chs[4], stride=2, drop=drop_block)     # 14  -> 7\n",
    "\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.head_drop = nn.Dropout(p=drop_head)\n",
    "\n",
    "        feat_dim = chs[-1]\n",
    "        if multitask:\n",
    "            self.head_fruit = nn.Linear(feat_dim, num_fruit)\n",
    "            self.head_fresh = nn.Linear(feat_dim, num_fresh)\n",
    "        else:\n",
    "            assert num_classes is not None, \"num_classes ë¥¼ ì§€ì •í•˜ì„¸ìš” (ë‹¨ì¼ ê³¼ì œ ëª¨ë“œ).\"\n",
    "            self.head = nn.Linear(feat_dim, num_classes)\n",
    "\n",
    "        # ê°„ë‹¨ ì´ˆê¸°í™”\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.trunc_normal_(m.weight, std=0.02)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "        x = self.stem(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)              # (B, C, 7, 7)\n",
    "        x = self.gap(x).squeeze(-1).squeeze(-2)  # (B, C)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.head_drop(x)\n",
    "\n",
    "        if self.multitask:\n",
    "            return self.head_fruit(x), self.head_fresh(x)\n",
    "        else:\n",
    "            return self.head(x), None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3952ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ==== AMP on/offë¥¼ ë””ë°”ì´ìŠ¤ì— ë§ì¶° ì•ˆì „í•˜ê²Œ ====\n",
    "def amp_enabled(device: torch.device) -> bool:\n",
    "    return getattr(Cfg, \"MIXED_PRECISION\", True) and device.type == \"cuda\"\n",
    "\n",
    "\n",
    "def loss_single(logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    return F.cross_entropy(logits, targets)\n",
    "\n",
    "def loss_multi(\n",
    "    logits_fruit: torch.Tensor, targets_fruit: torch.Tensor,\n",
    "    logits_fresh: torch.Tensor, targets_fresh: torch.Tensor,\n",
    "    alpha: float = 1.0, beta: float = 1.0\n",
    ") -> torch.Tensor:\n",
    "    lf = F.cross_entropy(logits_fruit, targets_fruit)\n",
    "    ls = F.cross_entropy(logits_fresh, targets_fresh)\n",
    "    return alpha * lf + beta * ls\n",
    "\n",
    "def _get_logits(outputs):\n",
    "    return outputs[0] if isinstance(outputs, (tuple, list)) else outputs\n",
    "\n",
    "\n",
    "def train_loop(model: nn.Module,\n",
    "               train_loader: torch.utils.data.DataLoader,\n",
    "               val_loader: Optional[torch.utils.data.DataLoader],\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               epochs: int,\n",
    "               device: torch.device,\n",
    "               multitask: bool = False,\n",
    "               scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,\n",
    "               grad_clip: Optional[float] = None):\n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        gpu_name = torch.cuda.get_device_name(device)\n",
    "        print(f\" Using GPU: {gpu_name}\")\n",
    "        print(f\"    CUDA capability: {torch.cuda.get_device_capability(device)}\")\n",
    "        print(f\"    Memory: {torch.cuda.get_device_properties(device).total_memory / 1024**3:.1f} GB\\n\")\n",
    "    else:\n",
    "        print(\"  Using CPU (no CUDA available)\\n\") #í™•ì¸ìš© ì½”ë“œì„\n",
    "\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=amp_enabled(device))\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        running_loss = 0.0\n",
    "        running_correct, running_total = 0, 0\n",
    "\n",
    "        loop = tqdm(train_loader, desc=f\"[Train] {epoch}/{epochs}\", leave=True)\n",
    "        for batch in loop:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            if multitask:\n",
    "                images, (y_fruit, y_fresh) = batch\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                y_fruit = y_fruit.to(device, non_blocking=True).long()\n",
    "                y_fresh = y_fresh.to(device, non_blocking=True).long()\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp_enabled(device)):\n",
    "                    logits_fruit, logits_fresh = model(images)\n",
    "                    loss = ce(logits_fruit, y_fruit) + ce(logits_fresh, y_fresh)\n",
    "\n",
    "                preds = logits_fruit.argmax(dim=1)\n",
    "                running_correct += (preds == y_fruit).sum().item()\n",
    "                running_total   += y_fruit.size(0)\n",
    "\n",
    "            else:\n",
    "                images, y = batch\n",
    "                images = images.to(device, non_blocking=True)\n",
    "                y = y.to(device, non_blocking=True).long()\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp_enabled(device)):\n",
    "                    outputs = model(images)\n",
    "                    logits  = _get_logits(outputs)\n",
    "                    loss    = ce(logits, y)\n",
    "\n",
    "                preds = logits.argmax(dim=1)\n",
    "                running_correct += (preds == y).sum().item()\n",
    "                running_total   += y.size(0)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            if grad_clip is not None:\n",
    "                scaler.unscale_(optimizer)\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            running_loss += float(loss.detach().cpu())\n",
    "            loop.set_postfix(loss=f\"{loss.item():.4f}\",\n",
    "                             lr=f\"{optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module,\n",
    "             loader: torch.utils.data.DataLoader,\n",
    "             device: torch.device,\n",
    "             multitask: bool = False) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    ce = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    if multitask:\n",
    "        # ë©€í‹°íƒœìŠ¤í¬ì˜ ê²½ìš° ê³¼ì¼ í—¤ë“œë§Œ F1 ê³„ì‚°\n",
    "        for images, (y_fruit, y_fresh) in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            y_fruit = y_fruit.to(device, non_blocking=True).long()\n",
    "            y_fresh = y_fresh.to(device, non_blocking=True).long()\n",
    "\n",
    "            logits_fruit, logits_fresh = model(images)\n",
    "            loss = ce(logits_fruit, y_fruit) + ce(logits_fresh, y_fresh)\n",
    "            total_loss += float(loss.detach().cpu())\n",
    "\n",
    "            preds = logits_fruit.argmax(dim=1).cpu().numpy()\n",
    "            labels = y_fruit.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')  # macro F1\n",
    "        return {\"val_loss\": total_loss / max(1, len(loader)),\n",
    "                \"val_f1\": f1}\n",
    "\n",
    "    else:\n",
    "        # ë‹¨ì¼ ê³¼ì œ (ë‹¤ì¤‘í´ë˜ìŠ¤ ë¶„ë¥˜)\n",
    "        for images, y in loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            y = y.to(device, non_blocking=True).long()\n",
    "\n",
    "            outputs = model(images)\n",
    "            logits = _get_logits(outputs)\n",
    "            loss = ce(logits, y)\n",
    "            total_loss += float(loss.detach().cpu())\n",
    "\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            labels = y.cpu().numpy()\n",
    "\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels)\n",
    "\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')  # ë‹¤ì¤‘í´ë˜ìŠ¤ìš© macro\n",
    "        return {\"val_loss\": total_loss / max(1, len(loader)),\n",
    "                \"val_f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "481159a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_5344\\3923261510.py:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=amp_enabled(device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Using GPU: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "    CUDA capability: (8, 9)\n",
      "    Memory: 8.0 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Train] 1/10:   0%|          | 0/671 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      6\u001b[39m model = SmallCNN(num_classes=Cfg.NUM_CLASSES, multitask=\u001b[38;5;28;01mFalse\u001b[39;00m).to(device)\n\u001b[32m      8\u001b[39m optimizer = torch.optim.AdamW(model.parameters(), lr=Cfg.LR, weight_decay=\u001b[32m5e-4\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m           \u001b[49m\u001b[43mmultitask\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_clip\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mtrain_loop\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, epochs, device, multitask, scheduler, grad_clip)\u001b[39m\n\u001b[32m     49\u001b[39m running_correct, running_total = \u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m\n\u001b[32m     51\u001b[39m loop = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Train] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, leave=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmultitask\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rkdrn\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rkdrn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rkdrn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1492\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1495\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rkdrn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rkdrn\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1272\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1287\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rkdrn\\anaconda3\\Lib\\queue.py:213\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._qsize():\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ShutDown\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rkdrn\\anaconda3\\Lib\\threading.py:363\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    365\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "Cfg.MULTITASK   = False\n",
    "Cfg.NUM_CLASSES = 14\n",
    "\n",
    "model = SmallCNN(num_classes=Cfg.NUM_CLASSES, multitask=False).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=Cfg.LR, weight_decay=5e-4)\n",
    "\n",
    "train_loop(model, train_loader, val_loader, optimizer, Cfg.EPOCHS, device,\n",
    "           multitask=False, scheduler=None, grad_clip=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96692fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_names = [\"ì‚¬ê³¼\", \"ë°”ë‚˜ë‚˜\", \"í† ë§ˆí† \", \"ë°°\", \"í¬ë„\"]  # ì¶”í›„ ìˆ˜ì •\n",
    "fresh_status = [\"ì‹ ì„ \", \"ìƒí•¨\"]\n",
    "\n",
    "def predict(model, image):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = image.to(device).unsqueeze(0)  # [1, C, H, W]\n",
    "        outputs = model(image)\n",
    "        pred = torch.argmax(outputs, dim=1).item()\n",
    "\n",
    "        fruit_idx = pred // 2\n",
    "        status_idx = pred % 2\n",
    "        return f\"{fruit_names[fruit_idx]} - {fresh_status[status_idx]}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
